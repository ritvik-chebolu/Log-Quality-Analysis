import os
import re
from typing import List
import spacy
from joblib import load

# !!! Autogenerated !!! Do not change. Path where this python file is located
home = os.path.dirname(os.path.realpath(__file__))

# !!! Autogenerated !!! Do not change the class name
class QulogSmRf:
    def __init__(self): 
        # !!! Autogenerated !!! Do not change.
        self.model = self.load(os.path.join(home, './model'))
        self.nlp = spacy.load('en_core_web_sm')

        self._pattern = r' +|=|_|\.'
        self._flags = re.UNICODE | re.MULTILINE | re.DOTALL
        self._regexp = re.compile(self._pattern, self._flags)

        self._stopwords = {
            'while', "hadn't", 'her', 'no', 'too', 
            'yourselves', 'why', 'themselves', "it's", 
            'y', 'those', "don't", 'here', 'some', 'doesn', 
            'him', 'at', 'is', "haven't", 'then', 'their', 'to', 
            'between', 'when', 'shouldn', 'by', 'be', 'during', 
            'weren', "hasn't", 'with', 'theirs', 'hers', 'and', 
            'can', "you'll", 'i', 't', 'will', 'above', 'ours', 
            'than', "should've", 'shan', 'that', 'few', 'mightn', 
            'what', 'most', 'an', "you've", 'if', 'again', 'we', 
            'against', 'didn', 'a', "won't", 'he', 'very', 'haven', 
            'you', 'both', 'from', "you're", 'these', 'further', 
            's', 'over', "didn't", 'wouldn', 'm', "mustn't", 'hasn', 
            "she's", 'his', 'my', "couldn't", 'same', "isn't", 'had', 
            'there', 'the', 'mustn', 'up', "mightn't", "wouldn't", 
            'does', 'don', "needn't", 'll', 'were', 'hadn', 'so', 
            'yourself', 'herself', 'them', 'whom', 'of', 'down', 
            'aren', 'off', 'through', "aren't", 'other', 'or', 'should', 
            'yours', 'doing', 'only', 'once', 'ain', 'couldn', 'now', 
            "weren't", 'into', 'she', 'all', 'having', 'needn', "shan't", 
            'won', 'your', 'before', 'been', 'such', 'where', 'they', 
            'for', 'am', 'just', "wasn't", 'ourselves', 'itself', 
            'isn', 'on', 'ma', 'was', 'more', 'until', 'own', 
            'who', 'being', 'below', 'did', 'but', 'has', 've', 
            'do', 'nor', 'this', 'himself', 'are', 'under', 'd', 'it', 
            'which', "shouldn't", "you'd", 'each', 'its', 'our', 'about', 
            'have', "doesn't", 'how', 'not', 'o', 'myself', 'because', 
            "that'll", 'after', 'any', 'out', 'me', 'wasn', 'in', 'as', 're'
        }

    # !!! Autogenerated !!! Do not change the method name.
    def load(self, model_file_path):
        return load(model_file_path)

    def _get_sm_embedding(self, doc):
        return doc.vector


    def _get_sm_embeddings(self, trf_docs):
        embeddings = []
        for doc in trf_docs:
            embeddings.append(self._get_sm_embedding(doc))
        return embeddings

    def _preprocess_log(self, log_line):
        if log_line:
            tokens = self._regexp.split(log_line)
            tokens = [tok.lower() for tok in tokens if tok and tok.isalpha() and tok not in self._stopwords]
            return tokens
        else:
            return None

    def _preprocess_logs(self, log_lines):
        result = []
        for ll in log_lines:
            ll = self._preprocess_log(ll)
            if ll:
                result.append(" ".join(ll))
        return result

    def _get_word_class_embeddings(self, log_lines):
        docs = list(self.nlp.pipe(log_lines))
        word_classses = [" ".join([t.pos_ for t in doc]) for doc in docs]
        word_classs_trf_docs = list(self.nlp.pipe(word_classses))
        word_class_embeddings = self._get_sm_embeddings(word_classs_trf_docs)
        return word_class_embeddings

    # !!! Autogenerated !!! Do not change the method name.
    def predict(self, log_line: str):
        return self.predict_batch([log_line])[0]

    # !!! Autogenerated !!! Do not change the method name.
    def predict_batch(self, log_lines: List[str]):
        log_lines = self._preprocess_logs(log_lines)
        word_class_embeddings = self._get_word_class_embeddings(log_lines)
        predictions = self.model.predict(word_class_embeddings)
        return predictions


# !!! Autogenerated !!! This will be used as a simple functionality test
if __name__ == "__main__":
    q = QulogSmRf()
    s = "Hello world"
    p1 = q.predict(s)
    p2 = q.predict_batch([s])
    print("Prediction for '{}': {}".format(s, p1))
    print("Prediction for '{}': {}".format(s, p2[0]))